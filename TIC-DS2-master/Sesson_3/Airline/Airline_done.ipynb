{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the existing \"2008.csv\" file in the directory could be the smaller version of the original.\n",
    "Consider downloading full-size file from http://stat-computing.org/dataexpo/2009/2008.csv.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T09:02:45.047279Z",
     "start_time": "2018-08-23T09:02:16.236087Z"
    }
   },
   "outputs": [],
   "source": [
    "# import neccessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# show plot intermediately under the calling cell\n",
    "%matplotlib inline\n",
    "\n",
    "# disable some warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action = \"ignore\")\n",
    "\n",
    "# set to unlimited column display:\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# import database\n",
    "df = pd.read_csv('2008.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Table: (sample) Dataframe including column dtype</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dtypes = pd.Series(df.dtypes,name='dtypes')\n",
    "df.head(2).append(dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "<center>Figure: Correlation Matrix of some columns</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr_matr(df, figsize=(10, 8)):\n",
    "    \"\"\"\n",
    "    Plot Correlation matrix using Seaborns heatmap\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pandas.DataFrame\n",
    "\n",
    "    figsize: tuple\n",
    "        size of the whole plot\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    corr = df.corr().round(2)\n",
    "    # mask = np.zeros_like(corr)\n",
    "    # mask[np.triu_indices_from(mask)] = True\n",
    "    sns.heatmap(\n",
    "        corr,\n",
    "        cmap=\"seismic\",\n",
    "        square=True,\n",
    "        xticklabels=corr.columns.values,\n",
    "        yticklabels=corr.columns.values,\n",
    "        center=0,\n",
    "        annot=True)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "    \n",
    "plot_corr_matr(df.loc[:,'DepTime':'Distance'])\n",
    "# plot_corr_matr(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//////// _From the graph above, which features, in your opinions, should be removed, which should be kept, why?_\n",
    "\n",
    "## 1st\n",
    "\n",
    "-To classify whether a flight is late or not, choose __ArrTime as the label__.\n",
    "\n",
    "-__ArrTime__, and __DepTime__ although have high correlation (0.72) but still not enough, we leave it to PCA to eliminate collinearity.\n",
    "\n",
    "-__CRSArrTime__ and __ArrTime__ also has 0.87 correlation score, we just keep __ArrTime__ as it is the real time data.\n",
    "\n",
    "-__ActualElapsedTime, CRSElapedTime, AirTime__ and __Distance__ have very high correlation (>0.95) so we can just keep one feature (Distance) as predictor.\n",
    "\n",
    "-__CRSDepTime__ and __DepTime__ also has 0.97 correlation score, we just keep __DepTime__ as it is the real time data.\n",
    "\n",
    "-__DepDelay__ is a predictor and __ArrDelay__ is a lable. __DepDelay__ and __ArrDelay__ have very high correlation (0.93).\n",
    "So we want to see if other features can be a good predictors to ArrDelay, __delete DepDelay is the choice__.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete CRSDepTime, CRSArrTime, ActualElapsedTime, CRSElapsedTime, AirTime, DepDelay\n",
    "del df['CRSDepTime']\n",
    "del df['CRSArrTime']\n",
    "del df['ActualElapsedTim']\n",
    "del df['CRSElapsedTime']\n",
    "del df['AirTime']\n",
    "del df['DepDelay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns:\n",
    "df = df.loc[:,'DepTime':'Distance']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "////////// End the 1st request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Table: Describe database</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.describe(include='all').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. NaN Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Table: Recheck describe columns with NaN values</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T09:03:17.952641Z",
     "start_time": "2018-08-23T09:02:48.558977Z"
    },
    "hide_input": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "def desc_nan(df):\n",
    "    \"\"\"\n",
    "    Show a table that describe about all columns of @df that contain NaN.\n",
    "    \"\"\"\n",
    "    row, col = df.shape\n",
    "    nas = row - df.describe(include='all').T['count']\n",
    "    nas = nas[nas > 0]\n",
    "    ps = nas / row * 100\n",
    "    ms = df.mode().iloc[0]\n",
    "    nadf = pd.DataFrame(data={\n",
    "        'Na Count': nas,\n",
    "        'Na Percentage': ps,\n",
    "        'mode': ms\n",
    "    }).loc[nas.index]\n",
    "    dnadf = df.describe().T.reindex(nadf.index)\n",
    "    nadf = pd.concat([nadf, dnadf.iloc[:, 1:]], axis=1)\n",
    "    display(nadf)\n",
    "\n",
    "desc_nan(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Figure: Distribution plot of all numeric columns</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ft_dist(df, fig_height=4, no_of_col=2,verbose=True):\n",
    "    \"\"\"\n",
    "    Plot distribution of all numeric columns in df\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pandas.DataFrame\n",
    "\n",
    "    fig_height: int\n",
    "\n",
    "    no_of_col: int\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    # prepare df\n",
    "    cat_cols = list(df.dtypes[df.dtypes == 'object'].index)\n",
    "    if verbose:\n",
    "        print(\"Ignored categorical columns: \", cat_cols)\n",
    "        print(\"\")\n",
    "    df_hasnan = df.isna().any().any()\n",
    "    if df_hasnan:\n",
    "        nan_cols = list(df.loc[:,df.isna().any()].columns)\n",
    "        df.dropna(inplace=True, axis=1)\n",
    "        if verbose:\n",
    "            print(\"dropped NaN cols:\", str(nan_cols))\n",
    "            print(\"\")\n",
    "    try:    \n",
    "        desc = df.describe().T\n",
    "        std0 = list(desc.loc[desc['std']==0].index)\n",
    "        if verbose:\n",
    "            print(\"dropped std=0 cols:\", str(std0))\n",
    "            print(\"\")\n",
    "        for col in std0:\n",
    "            del df[col]\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "    idx = df.dtypes[df.dtypes != 'object'].index\n",
    "    # prepare frame\n",
    "    f, axes = plt.subplots(\n",
    "        int(np.ceil(len(idx) / no_of_col)),\n",
    "        no_of_col,\n",
    "        figsize=(5 * no_of_col, np.ceil(len(idx) / no_of_col) * fig_height))\n",
    "    sns.set(style=\"white\", palette=\"muted\", color_codes=True)\n",
    "    n = 0\n",
    "    for i in idx:\n",
    "        sns.distplot(\n",
    "            df[i],\n",
    "            color='b',\n",
    "            hist=True,\n",
    "            kde_kws={\"shade\": True},\n",
    "            ax=axes[n // no_of_col, n % no_of_col])\n",
    "        n += 1\n",
    "    plt.show()\n",
    "\n",
    "plot_ft_dist(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "////// _Run codes above, describe what you see and start clean data / remove unimportant columns._\n",
    "\n",
    "## 2nd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete CRSDepTime, CRSArrTime, ActualElapsedTime, CRSElapsedTime, AirTime, DepDelay\n",
    "del df['CRSDepTime']\n",
    "del df['CRSArrTime']\n",
    "del df['ActualElapsedTim']\n",
    "del df['CRSElapsedTime']\n",
    "del df['AirTime']\n",
    "del df['DepDelay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns:\n",
    "df = df.loc[:,'DepTime':'Distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "////////// End the 2nd request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Table: (sample) Database after cleaning</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/////////// Give some insights, split train-test dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__DepTime, ArrTime__ are time values which if being stored in 10-based (decimal), their true values will be distorted (hours:minutes is not continuous on 10-based).\n",
    "#=> convert to minute integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert column to min:\n",
    "def to_min(n):\n",
    "    n = str(int(n))\n",
    "    if len(n)<=2:\n",
    "        return int(n)\n",
    "    else:\n",
    "        return int(n[:-2])*60+int(n[2:])\n",
    "df.DepTime=df.DepTime.apply(to_min)\n",
    "df.ArrTime=df.ArrTime.apply(to_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all float dtype columns to int64 dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if df[col].dtype == np.float:\n",
    "        df[col] = df[col].astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Table: (sample) Dataframe after dtype convertion</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtypes = pd.Series(df.dtypes,name='dtypes')\n",
    "df.head(2).append(dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2. One-hot-encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to pick which feature to use One-hot-encoding, we see how many unique data in each category data, then use boxplot to check the variation of ArrDelay by those features.\n",
    "<br><br>\n",
    "<center>Table: Unique value from each categorial feature</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(df.describe(include=\"O\").loc['unique']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/////// _start your code below to one hot encode or label encoding categorical features_\n",
    "\n",
    "## 3rd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"white\")\n",
    "f, ((ax1, ax2),(ax3, ax4)) = plt.subplots(2,2,sharex=True, squeeze=True, \n",
    "                                figsize=(10,10))\n",
    "\n",
    "sns.boxplot(x=\"ArrDelay\", y=\"UniqueCarrier\", data=df,\n",
    "            whis=np.inf, palette=\"vlag\",ax=ax1)\n",
    "\n",
    "sns.boxplot(x=\"ArrDelay\", y=\"TailNum\", data=df,\n",
    "            whis=np.inf, palette=\"vlag\",ax=ax2)\n",
    "\n",
    "sns.boxplot(x=\"ArrDelay\", y=\"Origin\", data=df,\n",
    "            whis=np.inf, palette=\"vlag\",ax=ax3)\n",
    "\n",
    "sns.boxplot(x=\"ArrDelay\", y=\"Dest\", data=df,\n",
    "            whis=np.inf, palette=\"vlag\", ax=ax4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that each __TailNum__ belongs to 1 __UniqueCarrier__. How late a flight is seems to more dependent on __UniqueCarrier__ than the __TailNum__. But we need to check this hypothesis by showing if there is any __TailNum__ that is NOT operated by 1 __UniqueCarrier__.\n",
    "<br><br>\n",
    "<center>Table: TailNum that is not operated by one UniqueCarrie</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is any TailNum that belongs to 2 UniqueCarriers\n",
    "pd.DataFrame(df.groupby('TailNum').UniqueCarrier.unique()\n",
    "                [df.groupby('TailNum').UniqueCarrier.unique()\n",
    "                     .apply(lambda x: len(x)!=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table rejects our hypothesis, but it shows only 2 instances of __TailNum__.\n",
    "The total number of records of N376CA and N379CA is 3171/6855024 (0.0462%) which is a very small affect (if any) on the prediction result. In addition, the amount of unique __TailNum__ is too large (5366) that might result in not having enough samples for each unique __TailNum__ (which makes the result more unreliable)\n",
    "\n",
    "__Origin__ or __Dest__ can be reliable predictors but currently we skip these rows for computational benefits.\n",
    "\n",
    "After finish analyzing those 4 categorial features, only 1 column to one-hot-encode is __UniqueCarrier__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot-encode UniqueCarrier column\n",
    "carrier = pd.get_dummies(df.UniqueCarrier)\n",
    "carrier.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "////////// End the 3rd request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Normalize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/////// _normalize / scale your data to range [0,1]\n",
    "\n",
    "## 4th\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of feature scaling, new table of normalized data (in range [0,1]) is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete categorical data:\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == np.object:\n",
    "        del df[col]\n",
    "\n",
    "# Normalize the df\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(df)\n",
    "X = pd.DataFrame(X, columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine normalized data with one-hot-encoded columns\n",
    "X = X.join(carrier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign ArrDelay in format of boolean, True if ArrDelay > 30 minutes\n",
    "Y = df.ArrDelay>30\n",
    "Y.reset_index(drop=True, inplace=True)\n",
    "del df['ArrDelay']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "////////// End the 4th request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Table: (sample) Predictor X (without PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Figure: Explaination ratio though dimensions using PCA and Cumulative explained variance table in details</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_PCA(df):\n",
    "    \"\"\"\n",
    "    Show the \"PCA ladder\" in order to pick the right\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pandas.DataFrame\n",
    "\n",
    "    fig_height: int\n",
    "\n",
    "    no_of_col: int\n",
    "    \"\"\"\n",
    "    from sklearn.decomposition import PCA\n",
    "\n",
    "    pca = PCA(n_components=len(df.columns))\n",
    "    pca.fit_transform(df)\n",
    "    # put data (predictor only) to pca and create pcadf\n",
    "    ratio = pca.explained_variance_ratio_\n",
    "\n",
    "    tot = sum(ratio)\n",
    "    var_exp = [(i / tot) for i in ratio]\n",
    "    cum_var_exp = np.cumsum(var_exp)\n",
    "\n",
    "    plt.bar(\n",
    "        range(0, len(df.columns)),\n",
    "        var_exp,\n",
    "        alpha=0.5,\n",
    "        align='center',\n",
    "        label='individual explained variance')\n",
    "    plt.step(\n",
    "        range(0, len(df.columns)),\n",
    "        cum_var_exp,\n",
    "        where='mid',\n",
    "        label='cumulative expalined variance')\n",
    "    plt.ylabel = 'Explained variance ratio'\n",
    "    plt.xlabel = 'Pricipal components'\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "    # show table with more details\n",
    "    pdf = pd.DataFrame(\n",
    "        [cum_var_exp],\n",
    "        columns=[\"dim {}\".format(i) for i in range(1,\n",
    "                                                   len(df.columns) + 1)])\n",
    "    display(pdf)\n",
    "    \n",
    "    \n",
    "plot_PCA(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//////////// the code below has \"n\" as dimensions to reduce to, decide that number so the total explation ratio > 0.95\n",
    "\n",
    "## 5th\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# create a PCA to reduce dimension to n\n",
    "n = # ?????\n",
    "pca = PCA(n_components=n)\n",
    "# put data (predictor only) to pca and create pcadf\n",
    "X = pd.DataFrame(pca.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get random 100_000 samples records from full dataset to tune\n",
    "x_tune = X.sample(n=100_000, random_state=25)\n",
    "y_tune = Y.sample(n=100_000, random_state=25)\n",
    "\n",
    "# get random 1_250_000 samples records from full dataset\n",
    "# that differ from the x_100k and y_100k\n",
    "x = (X[~X.index.isin(x_tune.index)]\n",
    "        .sample(n=1_250_000, random_state=25))\n",
    "y = (Y[~Y.index.isin(x_tune.index)]\n",
    "        .sample(n=1_250_000, random_state=25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the train and test data.\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "                        x, y, test_size=0.2, random_state=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//////// End the 5th request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed database to a csv file\n",
    "import os\n",
    "os.chdir(r'.\\working_database')\n",
    "\n",
    "x_tune.to_csv('x_tune.csv')\n",
    "pd.DataFrame(y_tune).to_csv('y_tune.csv')\n",
    "x_train.to_csv('x_train.csv')\n",
    "pd.DataFrame(y_train).to_csv('y_train.csv')\n",
    "x_test.to_csv('x_test.csv')\n",
    "pd.DataFrame(y_test).to_csv('y_test.csv')\n",
    "\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import neccessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# show plot intermediately under the calling cell\n",
    "%matplotlib inline\n",
    "\n",
    "# disable some warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action = \"ignore\")\n",
    "\n",
    "# set to unlimited column display:\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Load processed database from a csv file\n",
    "import os\n",
    "os.chdir(r'.\\working_database')\n",
    "\n",
    "x_tune = pd.read_csv('x_tune.csv', index_col=0)\n",
    "y_tune = pd.read_csv('y_tune.csv', index_col=0)\n",
    "x_train = pd.read_csv('x_train.csv', index_col=0)\n",
    "y_train = pd.read_csv('y_train.csv', index_col=0)\n",
    "x_test = pd.read_csv('x_test.csv', index_col=0)\n",
    "y_test = pd.read_csv('y_test.csv', index_col=0)\n",
    "\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following model will use default parameters and sample classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the model and fit the train database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print('Classification_report: \\n', \n",
    "      classification_report(\n",
    "          y_true=y_test,\n",
    "          y_pred=nb.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "////// Search google for \"sklearn logistics regression\" / decision tree / svm and figure out how to work on below parts\n",
    "\n",
    "## 6th\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(penalty='l2', # 'l1'\n",
    "                        C = 1.0) # float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Defind the parameter values that should be searched\n",
    "C_list = [0.1, 1, 10, 100, 1000]\n",
    "penalty_list = ['l1','l2']\n",
    "solver_list = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "\n",
    "# Create a parameter grid: map the parameter names to the\n",
    "# values that should be searched:\n",
    "param_grid = dict(C=C_list,\n",
    "                 penalty=penalty_list,\n",
    "                 solver=solver_list)\n",
    "# Instantiate the grid:\n",
    "grid = GridSearchCV(lr, param_grid, cv=10, error_score=0.0,\n",
    "                    scoring='f1_weighted', n_jobs=16)\n",
    "\n",
    "# fit the grid with data\n",
    "grid.fit(x_tune, y_tune)\n",
    "\n",
    "# examine the best model\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "\n",
    "# gre = Gridsearchcv REsult\n",
    "gre = pd.DataFrame(grid.cv_results_)\n",
    "(gre.loc[gre.mean_test_score!=0] # skip zero scored rows\n",
    "     [['rank_test_score','mean_fit_time','mean_test_score'] # get these col\n",
    "          +['param_{}'.format(i) for i in grid.best_params_.keys()]]\n",
    "    .sort_values('rank_test_score')) # sort by rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(C=0.1,\n",
    "                        penalty='l1',\n",
    "                        solver='liblinear')\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('Classification_report: \\n', \n",
    "      classification_report(\n",
    "          y_true=y_test,\n",
    "          y_pred=lr.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(criterion='gini', # 'entropy'\n",
    "                             min_samples_leaf=1, # float\n",
    "                             class_weight=None # 'balance'\n",
    "                             ) \n",
    "# tree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Defind the parameter values that should be searched\n",
    "criterion_list = ['gini','entropy']\n",
    "min_samples_leaf_list = [1,2,4,6,8,10]\n",
    "class_weight_list = [None,'balanced']\n",
    "# Create a parameter grid: map the parameter names to the\n",
    "# values that should be searched:\n",
    "param_grid = dict(criterion=criterion_list,\n",
    "                 min_samples_leaf=min_samples_leaf_list,\n",
    "                 class_weight=class_weight_list)\n",
    "\n",
    "# Instantiate the grid:\n",
    "grid = GridSearchCV(tree, param_grid, cv=10, \n",
    "                    scoring='f1_weighted', n_jobs=16)\n",
    "\n",
    "# fit the grid with data\n",
    "grid.fit(x_tune, y_tune)\n",
    "\n",
    "# examine the best model\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "\n",
    "# gre = Gridsearchcv REsult\n",
    "gre = pd.DataFrame(grid.cv_results_)\n",
    "(gre.loc[gre.mean_test_score!=0] # skip zero scored rows\n",
    "     [['rank_test_score','mean_fit_time','mean_test_score'] # get these col\n",
    "          +['param_{}'.format(i) for i in grid.best_params_.keys()]]\n",
    "    .sort_values('rank_test_score')) # sort by rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(criterion='entropy',\n",
    "                              min_samples_leaf=2,\n",
    "                              class_weight=None)\n",
    "                              \n",
    "tree.fit(x_train, y_train)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('Classification_report: \\n', \n",
    "      classification_report(\n",
    "          y_true=y_test,\n",
    "          y_pred=nb.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(C = 1.0,       # float\n",
    "         kernel = 'rbf', # 'linear','poly', 'sigmoid'\n",
    "         gamma = 'auto') # float\n",
    "# svm.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Defind the parameter values that should be searched\n",
    "C_list = [1,10,100,1000]\n",
    "kernel_list = ['rbf','linear','poly','sigmoid']\n",
    "gamma_list = ['auto', 10, 0.2]\n",
    "# Create a parameter grid: map the parameter names to the\n",
    "# values that should be searched:\n",
    "param_grid = dict(C=C_list,\n",
    "                  kernel=kernel_list,\n",
    "                  gamma=gamma_list)\n",
    "\n",
    "# Instantiate the rand:\n",
    "rand = RandomizedSearchCV(svm, param_grid, cv=5, \n",
    "                         scoring='f1_weighted', n_jobs=16,\n",
    "                         n_iter=5, random_state=25)\n",
    "\n",
    "# fit the rand with data\n",
    "rand.fit(x_tune, y_tune)\n",
    "\n",
    "# examine the best model\n",
    "print(rand.best_score_)\n",
    "print(rand.best_params_)\n",
    "\n",
    "# gre = Gridsearchcv REsult\n",
    "gre = pd.DataFrame(rand.cv_results_)\n",
    "(gre.loc[gre.mean_test_score!=0] # skip zero scored rows\n",
    "     [['rank_test_score','mean_fit_time','mean_test_score'] # get these col\n",
    "          +['param_{}'.format(i) for i in rand.best_params_.keys()]]\n",
    "    .sort_values('rank_test_score')) # sort by rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='rbf')               \n",
    "svm.fit(x_train, y_train)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('Classification_report: \\n', \n",
    "      classification_report(\n",
    "          y_true=y_test,\n",
    "          y_pred=svm.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "////////// End the 6th request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Z. Other\n",
    "Additional parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z.1. Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a model into a pickle file.\n",
    "import pickle\n",
    "import os\n",
    "os.chdir(r'.\\saved_models')\n",
    "pickle.dump(svm, open( \"svm.model\", \"wb\" ) )\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model back from the pickle file.\n",
    "import pickle\n",
    "import os\n",
    "os.chdir(r'.\\saved_models')\n",
    "lr = pickle.load(open(\"lr.model\", \"rb\"))\n",
    "nb = pickle.load(open(\"nb.model\", \"rb\"))\n",
    "rf = pickle.load(open(\"rf.model\", \"rb\"))\n",
    "tree = pickle.load(open(\"tree.model\", \"rb\"))\n",
    "svm = pickle.load(open(\"svm.model\", \"rb\"))\n",
    "os.chdir('..')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "283px",
    "left": "150px",
    "right": "20px",
    "top": "264px",
    "width": "498px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
